# Phoenix и schema.json

## Общая концепция
В проекте Phoenix используется как основа для хранения и обработки данных в HBase с поддержкой SQL-подобных запросов. Для корректного декодирования и трансформации данных из Phoenix в формат, пригодный для Kafka, применяется файл `schema.json`. Этот файл служит источником метаданных о структуре таблиц, колонках и типах данных, что позволяет точно интерпретировать бинарные данные из WAL-событий и формировать корректные значения для Kafka.

## schema.json
- **Где хранится**  
  Файл `schema.json` располагается в ресурсах проекта и загружается при инициализации сервиса через класс `JsonSchemaRegistry.java`.

- **Как выглядит структура**  
  `schema.json` представляет собой JSON-объект, содержащий описание схемы таблиц Phoenix. Основные ключи включают названия таблиц, описание колонок и их типов. Пример ключевого фрагмента:
  ```json
  {
    "tables": {
      "TBL_JTI_TRACE_CIS_HISTORY": {
        "columns": {
          "C":   { "type": "VARCHAR", "primaryKey": true },
          "T":   { "type": "UNSIGNED_TINYINT", "primaryKey": true },
          "OPD": { "type": "TIMESTAMP", "primaryKey": true },
          "DID": { "type": "VARCHAR" },
          "RID": { "type": "VARCHAR" }
        }
      }
    }
  }
  ```

- **Что описывает**  
  `schema.json` описывает таблицы Phoenix, их колонки, типы данных (например, INTEGER, VARCHAR, TIMESTAMP), а также информацию о первичных ключах. Это описание используется для правильного декодирования данных и формирования Value-сообщений в Kafka.

- **Используется при формировании Value в Kafka**  
  При обработке WAL-событий данные декодируются согласно схемам из `schema.json`, что обеспечивает корректное сопоставление бинарных данных с типами и именами колонок, и формирование итогового JSON-объекта для Kafka.

## SchemaRegistry / JsonSchemaRegistry
- **Класс `SchemaRegistry.java`: регистрация и работа со схемами**  
  `SchemaRegistry` служит интерфейсом для управления схемами. Он предоставляет методы для получения схем по имени таблицы, проверки наличия и валидации схем, что позволяет централизованно работать с метаданными.

- **Класс `JsonSchemaRegistry.java`: загрузка из `schema.json`**  
  `JsonSchemaRegistry` реализует `SchemaRegistry`, загружая схемы из файла `schema.json` при старте. Он парсит JSON, создает внутренние структуры данных и предоставляет методы доступа к схемам.

- **Связь с PayloadBuilder и декодированием**  
  `SchemaRegistry` используется в `PayloadBuilder` и декодерах для получения информации о колонках и типах данных, что необходимо для правильного формирования выходного JSON и корректного декодирования бинарных значений.

## ValueCodecPhoenix и вспомогательные компоненты
- **Orchestrator декодирования**  
  `ValueCodecPhoenix` агрегирует несколько специализированных компонентов:
  - `PhoenixColumnTypeRegistry` — нормализует строковые имена типов и кеширует `PDataType` по колонкам;
  - `PhoenixValueNormalizer` — приводит временные типы к epoch millis и сворачивает любые Phoenix-ARRAY в `List<Object>`;
  - `PhoenixPkParser` — разбирает rowkey c учётом соли и экранирования, нормализуя значения PK.

- **Обработка fixed/var типов, строгая валидация**  
  Кодек проверяет соответствие длины фиксированным типам (например, `UNSIGNED_INT = 4` байта) и выбрасывает `IllegalStateException` с детальной диагностикой при расхождениях.

- **Нормализация temporals и массивов**  
  Внутри `PhoenixValueNormalizer` все `TIMESTAMP/DATE/TIME` приводятся к `Long` (epoch millis), а любые массивы (включая примитивные) преобразуются в список без лишних копий.

- **Парсинг PK и rowkey**  
  `PhoenixPkParser` берёт список PK-колонок из `SchemaRegistry`, извлекает сегменты rowkey, снимает Phoenix-escape (`FF 00/FF`) и использует общий нормализатор времени. Поля PK автоматически инжектируются в итоговый JSON, их не нужно дублировать в `cf.list`.

## Decoder и RowKeySlice
- **Интерфейс Decoder и его контракт**  
  Интерфейс `Decoder` определяет методы для декодирования бинарных данных в объекты Java. Контракт включает методы для декодирования как ключей, так и значений, обеспечивая абстракцию над конкретными форматами данных.

- **RowKeySlice: вспомогательный класс для работы с бинарным rowkey**  
  `RowKeySlice` представляет собой класс-обертку над массивом байтов rowkey, предоставляя методы для извлечения частей ключа, сдвигов и длины, что упрощает декодирование составных ключей.

## Пример потока данных
1. WAL-событие из HBase поступает в систему.
2. `RowKeySlice` выделяет бинарный rowkey из события.
3. `Decoder`, `ValueCodecPhoenix` и `PhoenixPkParser` декодируют первичный ключ (PK) и значения колонок согласно типам.
4. `SchemaRegistry` проверяет и предоставляет схему из `schema.json` для соответствующей таблицы.
5. `PayloadBuilder` формирует итоговый JSON-объект, который отправляется в Kafka.

## Практические советы
- `schema.json` должен быть синхронизирован с актуальной схемой Phoenix, чтобы избежать ошибок декодирования.
- Добавление новых колонок в таблицы требует обновления `schema.json` и перезапуска сервиса для корректного распознавания новых полей.
- Следить за типами дат (Date, Time, Timestamp), так как они нормализуются в миллисекунды эпохи для единого формата представления времени.

См. также:
- [Конфигурация (все ключи)](config.md)
- [Подсказки ёмкости и метаданные](capacity.md)
